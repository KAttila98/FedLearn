{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd04adb31e4790d9d025a6596fce94fda67def9de9857543dcec674d39c55581d2c",
   "display_name": "Python 3.7.10 64-bit ('Nokia': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.loda_dumb import LODA\n",
    "from fed_loda import FedLODA\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, recall_score\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "shuttle = loadmat('shuttle/shuttle.mat')\n",
    "shuttle_df_orig = pd.DataFrame(shuttle['X'], columns=[f\"x{i}\" for i in range(1, 10)])\n",
    "shuttle_df_orig['y'] = shuttle['y']\n",
    "shuttle_df = shuttle_df_orig.sample(frac=1).reset_index(drop=True)\n",
    "datasets[\"shuttle\"] = shuttle_df\n",
    "\n",
    "\n",
    "satimage = loadmat('satimage/satimage-2.mat')\n",
    "satimage_df = pd.DataFrame(satimage['X'], columns=[f\"x{i}\" for i in range(1, 37)])\n",
    "satimage_df['y'] = satimage['y']\n",
    "datasets[\"satimage\"] = satimage_df\n",
    "\n",
    "\n",
    "musk = loadmat('musk/musk.mat')\n",
    "musk_df = pd.DataFrame(musk['X'], columns=[f\"x{i}\" for i in range(1, 167)])\n",
    "musk_df['y'] = musk['y']\n",
    "datasets[\"musk\"] = musk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = \"musk\"\n",
    "num_agents = 3\n",
    "data_tu_use = datasets[dataname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def feder_strat_split(df, k):\n",
    "    Xy_0 = np.array_split(df[df.iloc[:,-1]==0], k)\n",
    "    Xy_1 = np.array_split(df[df.iloc[:,-1]==1], k)\n",
    "    Xy = []\n",
    "    for i, j in zip(Xy_0, Xy_1):\n",
    "        Xy.append(pd.concat([i,j]))\n",
    "    \n",
    "    X_list=[]\n",
    "    y_list=[]\n",
    "    for sub in Xy:\n",
    "        X_list.append(sub.iloc[:,:-1])\n",
    "        y_list.append(sub.iloc[:,-1])\n",
    "    \n",
    "    X_train_l, X_test_l, y_train_l, y_test_l = [], [], [], []\n",
    "    for X, y in zip(X_list, y_list):\n",
    "        X_train, X_test, y_train, y_test =\\\n",
    "            train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "        X_train_l.append(X_train)\n",
    "        X_test_l.append(X_test)\n",
    "        y_train_l.append(y_train)\n",
    "        y_test_l.append(y_test)\n",
    "\n",
    "    assert len(X_train_l)==len(X_test_l)==len(y_train_l)==len(y_test_l)==k\n",
    "\n",
    "    for i, j in zip(X_train_l, y_train_l):\n",
    "        assert i.shape[0] == j.shape[0] \n",
    "    for i, j in zip(X_test_l, y_test_l):\n",
    "        assert i.shape[0] == j.shape[0] \n",
    "\n",
    "    return X_train_l, X_test_l, y_train_l, y_test_l\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(919, 166) (919,) 30.0\n(103, 166) (103,) 3.0\n(918, 166) (918,) 29.0\n(102, 166) (102,) 3.0\n(918, 166) (918,) 29.0\n(102, 166) (102,) 3.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = feder_strat_split(data_tu_use, num_agents)\n",
    "\n",
    "y_test_df = pd.concat(y_test)\n",
    "X_test_df = pd.concat(X_test)\n",
    "\n",
    "\n",
    "for i, j, k, l in zip(X_train, X_test, y_train, y_test):\n",
    "    print(i.shape, k.shape, k.sum())\n",
    "    print(j.shape, l.shape, l.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(307, 166) (307,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_df.shape, y_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<fed_loda.FedLODA at 0x7f6a016fa290>"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "    \n",
    "floda = FedLODA(\n",
    "n_random_cuts = 500, standardize=False\n",
    ")\n",
    "floda.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Agent_0:\n",
      "\n",
      "    \n",
      "\t {'accuracy': 0.29053318824809576, 'av_prec': 0.995766129032258, 'auc': 0.9998500187476566}\n",
      "\n",
      "    \n",
      "\t {'accuracy': 0.9477693144722524, 'av_prec': 0.19082862864522626, 'auc': 0.760217472815898}\n",
      "\n",
      "    \n",
      "\n",
      "Agent_1:\n",
      "\n",
      "    \n",
      "\t {'accuracy': 0.9771241830065359, 'av_prec': 0.562098385515666, 'auc': 0.9893720181529033}\n",
      "\n",
      "    \n",
      "\t {'accuracy': 0.9901960784313726, 'av_prec': 0.8899748140017899, 'auc': 0.9961987510181917}\n",
      "\n",
      "    \n",
      "\n",
      "Agent_2:\n",
      "\n",
      "    \n",
      "\t {'accuracy': 1.0, 'av_prec': 0.9999999999999998, 'auc': 1.0}\n",
      "\n",
      "    \n",
      "\t {'accuracy': 0.9880174291938998, 'av_prec': 0.9203013440310857, 'auc': 0.9967417865870215}\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\t {'accuracy': 0.5830618892508144, 'av_prec': 0.04782864111019545, 'auc': 0.6733780760626399}\n",
      "\n",
      "\n",
      "\t {'accuracy': 0.9576547231270358, 'av_prec': 0.3109789611885623, 'auc': 0.9205816554809844}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (x_tr, y_tr) in enumerate(zip(X_train, y_train)):\n",
    "    print(f\"\\nAgent_{i}:\")\n",
    "\n",
    "    metrics_tr = floda.models[i].valid_metrics(x_tr, y_tr)\n",
    "    fed_metrics_tr = floda.valid_metrics(x_tr, y_tr)\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    \\n\\t {metrics_tr}\\n\n",
    "    \\n\\t {fed_metrics_tr}\\n\n",
    "    \"\"\")\n",
    "\n",
    "metrics_te = floda.models[i].valid_metrics(X_test_df, y_test_df)\n",
    "fed_metrics_te = floda.valid_metrics(X_test_df, y_test_df)\n",
    "print(f\"\"\"\n",
    "\\n\\t {metrics_te}\\n\n",
    "\\n\\t {fed_metrics_te}\\n\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         Accuracy  Average precision       AUC\nLODA0    0.198697           0.934083  0.997390\nLODA1    0.635179           0.063147  0.767711\nLODA2    0.583062           0.047829  0.673378\nFedLODA  0.957655           0.310979  0.920582\n"
     ]
    }
   ],
   "source": [
    "metr = {\n",
    "    \"accuracy\": 'Accuracy',\n",
    "    'av_prec':\"Average precision\",\n",
    "    'auc': \"AUC\" \n",
    "}\n",
    "TEST_df = pd.DataFrame(columns=['Accuracy', \"Average precision\", \"AUC\"])\n",
    "for i in range(num_agents):\n",
    "    metrics_te = floda.models[i].valid_metrics(X_test_df, y_test_df)\n",
    "    TEST_df = TEST_df.append({metr[k]:v for k, v in metrics_te.items()}, ignore_index=True)\n",
    "\n",
    "\n",
    "fed_metrics_te = floda.valid_metrics(X_test_df, y_test_df)\n",
    "TEST_df = TEST_df.append({metr[k]:v for k, v in fed_metrics_te.items()}, ignore_index=True)\n",
    "TEST_df.index = [*[f\"LODA{i}\" for i in range(num_agents)], \"FedLODA\"]\n",
    "\n",
    "print(TEST_df)\n",
    "TEST_df.to_latex(f\"/mnt/c/Users/mateb/Dropbox/Apps/Overleaf/FedLearnHW/lodaontest_{dataname}.tex\", float_format=\"%.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 Accuracy Average precision            AUC\nLODA0/Fed.  0.2905/0.9478     0.9958/0.1908  0.9999/0.7602\nLODA1/Fed.  0.9771/0.9902       0.5621/0.89  0.9894/0.9962\nLODA2/Fed.      1.0/0.988        1.0/0.9203     1.0/0.9967\n"
     ]
    }
   ],
   "source": [
    "num_a = len(X_train)\n",
    "\n",
    "metr = {\n",
    "    \"accuracy\": 'Accuracy',\n",
    "    'av_prec':\"Average precision\",\n",
    "    'auc': \"AUC\" \n",
    "}\n",
    "TRAIN_df = pd.DataFrame(columns=['Accuracy', \"Average precision\", \"AUC\"])\n",
    "for i, (x_tr, y_tr) in enumerate(zip(X_train, y_train)):\n",
    "    metrics_te = floda.models[i].valid_metrics(x_tr, y_tr)\n",
    "\n",
    "    fed_metrics_te = floda.valid_metrics(x_tr, y_tr)\n",
    "    TRAIN_df = TRAIN_df.append({metr[k]:f\"{v1:.4}/{v:.4}\" for v1, (k, v) in zip(metrics_te.values(), fed_metrics_te.items())}, ignore_index=True)\n",
    "\n",
    "TRAIN_df.index = [f\"LODA{i}/Fed.\" for i in range(num_a)]\n",
    "\n",
    "print(TRAIN_df)\n",
    "\n",
    "TRAIN_df.to_latex(f\"/mnt/c/Users/mateb/Dropbox/Apps/Overleaf/FedLearnHW/lodaontrain_{dataname}.tex\", float_format=\"%.4f\")"
   ]
  }
 ]
}